\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{ngerman}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{a4wide}
		     
		      
\title{Praktikum Multicore-Programmierung \\ Abschlussprojekt 1}
\author{Gruppe 3: Sarah Lutteropp und Johannes Sailer}

\date{\today}
% Hinweis: \title{um was auch immer es geht}, \author{wer es auch immer 
% geschrieben hat} und  \date{wann auch immer das war} k\"onnen vor 
% oder nach dem  Kommando \begin{document} stehen 
% Aber der \maketitle Befehl mu\ss{} nach dem \begin{document} Kommando stehen! 
\begin{document}

\maketitle


\begin{abstract}
Dies ist eine Ausarbeitung für das Abschlussprojekt des Praktikums Multicore-Programmierung im Wintersemester 2015/16. Ziel des Projektes war es, am Beispiel des Jacobi-Verfahrens und des Gauß-Seidel-Verfahrens parallele Lösungsmethoden partieller Differentialgleichungen zu implementieren.
\end{abstract}

\section{Mathematischer Hintergrund}

%Wir haben folgendes Setting:
%\begin{itemize}
%	\item $\Omega \cup \Gamma = [0,1]^2$
%	\item Rand $\Gamma = \{(x,y) \in \mathbb{R}^2 : x \in \{0,1\} \text{ oder }  y \in \{0,1\} \}$
%	\item $-\Delta u(x,y) = f(x,y) \quad \forall (x,y) \in (0,1)^2$
%	\item $u(x,y) = 0 \quad \forall (x,y) \in [0,1]^2 \backslash (0,1)^2$
%	
%	\item Diskretisierungsparameter $h$
%	\item $(x,y)$ sind also Koordinaten im diskretisierten Einheitsquadrat
%	\item Vereinfachte Schreibweise: $u_{i,j} = u(x_i, y_j) \in \mathbb{R}$
%	\item $n$ ist die Anzahl der Gitterpunkte pro Dimension
%	\item Im Vektor $u^k \in \mathbb{R}^{n^2}$ stehen die Werte von $u$ für alle Gitterpunkte im Iterationsschritt $k$. Diese Notation ist echt doof, weil man das ständig mit der Funktion $u$ selbst verwechselt. :-(
%\end{itemize}

Anhand des Beispiels der Approximation von Stoffkonzentrationen innerhalb eines festgelegten zweidimensionalen durch ein Gitter angenäherten Gebietes ergibt sich mittels der auf dem Aufgabenblatt dargestellten Umformungen, Randbedingungen und Argumentationsschritte lineare Gleichungssystem $Au = b$, das wir mittels Iterationsverfahren lösen sollen.

Hierbei ist
$A = \begin{pmatrix}
T & -I &  &  &  \\ 
-I & T & -I &  &  \\ 
 & \ddots & \ddots & \ddots &  \\ 
 &  & -I & T & -I \\ 
 &  &  & -I & T \\ 
\end{pmatrix} \in \mathbb{Z}^{2n \times 2n}, \quad$
$T \in \mathbb{Z}^{TODO \times TODO}$ 

mit $T_{i,j} = \begin{cases} 4 & \text{falls } i = j \\ -1 & \text{falls } |i-j| = 1 \\ 0 & \text{sonst}\end{cases}, \quad$ 
$u = \begin{pmatrix}
u_{1,1} \\ 
\vdots \\
u_{n,n}
\end{pmatrix} \text{ und } b = h^2 * \begin{pmatrix}
f(x_1, y_1) \\ 
\vdots \\
f(x_n, y_n)
\end{pmatrix}.$

Es ist $h \leq 1$, $\frac{1}{h} \in \mathbb{N}$, $n = \frac{1}{h}-1$, $x_i = y_i = h*i$ für $i = 1, \ldots, n$ und $f : \mathbb{R} \to \mathbb{R}$ eine Funktion.

~\\

Für $h = \frac{1}{3}$ ergibt sich beispielsweise das folgende Gleichungssystem:

$$\begin{pmatrix}
4 & -1 & -1 & 0 \\ 
-1 & 4 & 0 & -1 \\ 
-1 & 0 & 4 & -1 \\ 
0 & -1 & -1 & 4
\end{pmatrix} *
\begin{pmatrix}
u_{1,1} \\ 
u_{1,2} \\ 
u_{2,1} \\ 
u_{2,2}
\end{pmatrix} = \left(\frac{1}{3}\right)^2 *
\begin{pmatrix}
f(1/3,1/3) \\ 
f(1/3,2/3) \\ 
f(2/3,1/3) \\ 
f(2/3,2/3)
\end{pmatrix}
$$

Man könnte dieses lineare Gleichungssystem natürlich auch mit direkten Verfahren wie dem Gaußschen-Eliminationsverfahren lösen. Dieses ist jedoch nur sehr schlecht parallelisierbar. Außerdem ist das Gaußsche-Eliminationsverfahren sehr anfällig für numerische Störungen. Das ist bei iterativen Verfahren normalerweise nicht der Fall.


\subsection{Jacobi-Verfahren}
Blabla
\subsubsection{Herleitung}
Blabla
\subsubsection{Abbruchkriterium} \label{jacobi:abbruch}
Blabla

\subsection{Gauß-Seidel-Verfahren}
Blabla
\subsubsection{Herleitung}
Blabla
\subsubsection{Abbruchkriterium}
Für das Gauß-Seidel-Verfahren haben wir dasselbe Abbruchkriterium wie in Abschnitt~\ref{jacobi:abbruch} verwendet. (TODO: Begründung)

\subsection{Vergleich der Konvergenz und Stabilität beider Verfahren}\label{konvergenz}
Blabla

\section{Sequentielle Implementierung}

Die Matrixeinträge werden in dem auf dem Aufgabenblatt zur Verfügung gestellten Pseudocode spaltenweise durchlaufen. Daher haben wir in unserer Implementierung die Matrizen spaltenweise indiziert, um eine möglichst gute Cache-Lokalität zu erzielen.

Anstatt des Parameters $h$ übergeben wir einen Parameter $size$, der $\frac{1}{h}+1$ entspricht. Dies hat den Vorteil, dass der Nutzer den Grad der Verfeinerung exakt ohne Gleitkommaungenauigkeiten angeben kann und $A$ eine $size \times size$-Matrix ist.
 
Da sich die Einträge des Vektors $b$ innerhalb der Iterationen nicht ändern, haben wir $b$ vorberechnet.

\subsection{Laufzeiten bei verschiedenen Verfeinerungen}
Blabla
\subsection{Approximationsfehler}
Blabla

\section{Parallelisierung}
Blabla
\subsection{Jacobi-Verfahren} \label{parallel:jacobi}
Da innerhalb der Iterationsschritte des Jacobi-Verfahrens keinerlei Datenabhängigkeiten bei der Berechnung der Matrixeinträge bestehen, haben wir mittels OpenMP (\texttt{\#pragma omp parallel for}) die äußere Schleife parallelisiert.

Hierbei haben wir folgenden Speedup bei verschiedenen Problemgrößen $h$ und sowie verschiedenen Prozessorzahlen $p$ gemessen: TODO

\subsection{Gauß-Seidel-Verfahren}

Innerhalb der Iterationsschritte des Gauß-Seidel-Verfahrens bestehen Datenabhängigkeiten, da die Berechnung der Matrixeinträge in einer Iteration von den vorher berechneten Einträgen der selben Iteration abhängt. Das Gauß-Seidel-Verfahren ist daher inhärent sequentiell. Daher ist eine Parallelisierung des Gauß-Seidel-Verfahrens mit mehr Aufwand verbunden als beim ``embarassingly parallel'' Jacobi-Verfahren.

Wir haben sowohl den naiven, falschen Parallelisierungsansatz als auch zwei verschiedene funktionierende Parallelisierungsansätze implementiert.

\subsubsection{Naiver Parallelisierungsansatz}\label{gs:naiv}
Der naive Parallelisierungsansatz ist, wie in Abschnitt~\ref{parallel:jacobi} die äußerste Schleife mittels \texttt{\#pragma omp parallel for} zu parallelisieren. Da eine parallele Ausführung der Schleifeniterationen mittels OpenMP nicht die Iterationsreihenfolge garantiert, kann es hierbei zu Wettlaufsituationen (``Race Conditions'') kommen.

Im Fall des Gauß-Seidel-Verfahrens tritt dies in folgendem Beispiel auf (TODO: Beispiel):


Der im Praktikum vorgestellte Intel Thread Sanitizer erkennt die auftretende Wettlaufsituation nicht.

\subsubsection{Erweiterter Parallelisierungsansatz: Rot-Schwarz}

Bei der Rot-Schwarz-Parallelisierung des Gauß-Seidel-Verfahrens wird ausgenutzt, dass jeder Matrixeintrag nur von seinem linken, rechten, oberen und unteren direkten Nachbarn abhängt. Wir färben also die Matrixeinträge in rote und schwarze Felder ein, wobei die Datenabhängigkeiten nur zwischen Einträgen unterschiedlicher Farbe bestehen. Hieraus ergibt sich ein Schachbrettmuster, wie in Abbildung TODO gezeigt.

Da die Matrixeinträge gleicher Farbe nicht voneinander abhängen, können wir diese parallel berechnen. Dies führt zu folgendem Ansatz: (TODO: Pseudocode)

Hierbei ist zu beachten, dass die einzelnen Iterationen des sequentiellen Gauß-Seidel-Verfahrens und dessen Rot-Schwarz-Parallelisierung nicht genau dasselbe Ergebnis liefern. Dies liegt darin begründet, dass durch die Rot-Schwarz-Aufteilung eine Umordnung der Matrixeinträge geschieht.

Um die Indexberechnung zu vereinfachen und die Cachelokalität zu verbessern, haben wir die roten und die schwarzen Einträge jeweils in eigenen, neuen Matrizen gespeichert. Dadurch liegen Einträge gleicher Farbe zusammenhängend im Speicher. Dies hat es uns auch ermöglicht, unsere Implementierung mittels SSE-Vektorinstruktionen zu beschleunigen.

Bei den Indexberechnungen haben wir zwischen $size \times size$-Matrizen gerader und ungerader $size$ unterschieden. Abbildung TODO zeigt die Berechnung der Nachbarindizes roter und schwarzer Einträge für gerade bzw. ungerade Werte von $size$.


\paragraph{Messung von Speedup und Effizienz unter verschiedenen Verfeinerungen, Skalierbarkeit}
TODO

\subsubsection{Erweiterter Parallelisierungsansatz: Wavefront}
Blabla, TODO: Johannes

\section{Methodenwahl}
Da das Gauß-Seidel-Verfahren schneller konvergiert als das Jacobi-Verfahren (siehe Abschnitt~\ref{konvergenz}) und zudem unsere parallele Implementierung des Gauß-Seidel-Verfahrens mittels Rot-Schwarz-Verfahren TODO

\end{document}
